# RawNetLite: Lightweight End-to-End Audio Deepfake Detection

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![PyTorch](https://img.shields.io/badge/framework-pytorch-yellow.svg)
![Python](https://img.shields.io/badge/python-3.10%2B-blue.svg)
![GitHub Repo stars](https://img.shields.io/github/stars/adipiz99/RawNetLite)
![GitHub Repo forks](https://img.shields.io/github/forks/adipiz99/RawNetLite)
![GitHub Repo watchers](https://img.shields.io/github/watchers/adipiz99/RawNetLite)
![GitHub contributors](https://img.shields.io/github/contributors/adipiz99/RawNetLite)
![GitHub repo size](https://img.shields.io/github/repo-size/adipiz99/RawNetLite)

This repository contains the official implementation of the paper:

> **End-to-end Audio Deepfake Detection from RAW Waveforms: a RawNet-Based Approach with Cross-Dataset Evaluation**  
> *Andrea Di Pierno, Luca Guarnera, Dario Allegra, Sebastiano Battiato*  
> In Proceedings of the **VERIMEDIA Workshop at IJCNN 2025**, Rome, Italy.

---

## ğŸ§  Overview

**RawNetLite** is a lightweight convolutional-recurrent model designed to detect audio deepfakes directly from raw waveforms, without relying on handcrafted features or large pretrained models.

The model is trained and evaluated under in-domain and cross-dataset scenarios using three public datasets: [FakeOrReal](https://www.kaggle.com/datasets/mohammedabdeldayem/the-fake-or-real-dataset), [AVSpoof2021](https://www.asvspoof.org/index2021.html), and [CodecFake](https://github.com/roger-tseng/CodecFake).

We introduce a training pipeline based on:

- **Raw waveform input**
- **Domain-mix learning**
- **Focal Loss optimization**
- **Waveform-level audio augmentations**

---

## ğŸ“„ Paper

If you use this code, please cite our paper:

```bibtex
@inproceedings{dipierno2025rawnetlite,
  title     = {End-to-end Audio Deepfake Detection from RAW Waveforms: a RawNet-Based Approach with Cross-Dataset Evaluation},
  author    = {Andrea Di Pierno and Luca Guarnera and Dario Allegra and Sebastiano Battiato},
  booktitle = {International Joint Conference on Neural Networks (IJCNN) - VERIMEDIA Workshop},
  year      = {2025}
}
```
## ğŸ“‚ Directory Structure
```bash
.
â”œâ”€â”€ models/                   # Pretrained models
    â”œâ”€â”€ rawnet_lite.pt                                      # Basic RawNetLite model
    â”œâ”€â”€ cross_domain_rawnet_lite.pt                         # Cross-domain RawNetLite model
    â”œâ”€â”€ cross_domain_focal_rawnet_lite.pt                   # Cross-domain RawNetLite with Focal Loss
    â”œâ”€â”€ triple_cross_domain_focal_rawnet_lite.pt            # Triple cross-domain RawNetLite with Focal Loss
    â”œâ”€â”€ augmented_triple_cross_domain_focal_rawnet_lite.pt  # Augmented triple cross-domain RawNetLite with Focal Loss
â”œâ”€â”€ .gitignore                # Git ignore file
â”œâ”€â”€ .gitattributes            # Git attributes file
â”œâ”€â”€ audio_preprocessor.py     # Audio preprocessing module
â”œâ”€â”€ AVSpoof_dataset.py        # AVSpoof PyTorch dataset
â”œâ”€â”€ CodecFake_dataset.py      # CodecFake PyTorch dataset
â”œâ”€â”€ focal_loss.py             # Focal loss implementation
â”œâ”€â”€ FOR_dataset.py            # FakeOrReal PyTorch dataset
â”œâ”€â”€ LICENSE                   # License file
â”œâ”€â”€ Mixed_dataset.py          # Mixed-domain PyTorch datasets
â”œâ”€â”€ RawNetLite.py             # Main model architecture
â””â”€â”€ README.md                 # This file
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ tester.py                 # Testing script
```
## ğŸ›  Installation
1. Clone the repository:

```bash
git clone https://github.com/adipiz99/rawnetlite.git
cd RawNetLite
```
2. Install the required packages:

```bash
pip install -r requirements.txt
```
---

## ğŸ” Preprocessing

To preprocess your dataset into waveform tensors (.pt):

```bash
python audio_preprocessor.py \
    --csv_path metadata.csv \
    --input_dir path/to/audio \
    --output_root data/audio_processed/
```

This will create `real_processed/` and `fake_processed/` folders with normalized, trimmed, and resampled audio waveforms.

---

## ğŸ§ª Evaluation

To run the test bench and evaluate all models across all datasets:

```bash
python tester.py
```

The script outputs:
- Classification metrics (Precision, Recall, F1)
- Equal Error Rate (EER) and threshold
- Support for FakeOrReal, AVSpoof2021, CodecFake, and mixed-domain evaluations

---

## ğŸ¯ Pretrained Models

Pretrained have been released into the `models/` folder.

---

## ğŸ—‚ Datasets

This repository supports the following datasets:
- [FakeOrReal](https://www.kaggle.com/datasets/mohammedabdeldayem/the-fake-or-real-dataset)
- [AVSpoof2021](https://www.asvspoof.org/index2021.html)
- [CodecFake](https://github.com/roger-tseng/CodecFake)

Each must be preprocessed using the provided script. Ensure correct splits for training and evaluation.

---

## âš– License

This project is licensed under the MIT License. See the `LICENSE` file for details.

---

## ğŸ“¬ Contact

If you have questions or find this project useful, feel free to contact us:

- Andrea Di Pierno â€” [andrea.dipierno@imtlucca.it](mailto:andrea.dipierno@imtlucca.it)

---

## ğŸ“Œ Acknowledgments

This research is part of the National Ph.D. in Cybersecurity (Italy) and was supported by the Department of Mathematics and Computer Science, University of Catania, and IMT School for Advanced Studies Lucca.